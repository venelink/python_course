{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Linguists\n",
    "\n",
    "Notebook 8: POS Tagging\n",
    "\n",
    "Venelin Kovatchev\n",
    "\n",
    "University of Barcelona 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will see how we can do Part of Speech Tagging using NLTK.\n",
    "\n",
    "We will see different taggers and the importance of the choice of corpus.\n",
    "\n",
    "We will also learn some more about functions and function variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the important packages for today\n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all resources needed for today\n",
    "from nltk import bigrams, trigrams\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import codecs\n",
    "import codecs\n",
    "\n",
    "# Import taggers\n",
    "from nltk import DefaultTagger, AffixTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk import ClassifierBasedPOSTagger\n",
    "\n",
    "# Import the brown corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced functions\n",
    "\n",
    "# Before moving to POS tagging, lets' first observe the the behavior of a very simple function\n",
    "\n",
    "var_1 = \"Boo\"\n",
    "var_2 = \"Hoo\"\n",
    "var_3 = \"DooDoo\"\n",
    "\n",
    "def my_simple_function(atr_1, atr_2, atr_3 = \"ignore me\"):\n",
    "    \n",
    "    print(\"My atr_1 is:\" + str(atr_1))\n",
    "    print(\"My atr_2 is:\" + str(atr_2))\n",
    "    print(\"My atr_3 is:\" + str(atr_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how the function works\n",
    "my_simple_function(var_1, var_2, var_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we change the order?\n",
    "# As you can see, the function assigns variables based on their position\n",
    "my_simple_function(var_3, var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we don't add a third variable?\n",
    "my_simple_function(var_1, var_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we also don't add a second variable?\n",
    "my_simple_function(var_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we explicitly tell the function what is what?\n",
    "my_simple_function(atr_3 = var_1, atr_1 = var_2, atr_2 = var_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech tagging in python\n",
    "\n",
    "In this class we will see different ways to automatically tag a corpus with part of speech\n",
    "\n",
    "We will focus on ngram based taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all categories of the brown corpus\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tokenized and tagged version of the \"news\" category\n",
    "brown_twords = brown.tagged_words(categories='news')\n",
    "\n",
    "# Get the sentence segmented, tokenized, and tagged version of the \"news\" category\n",
    "brown_tsents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 5 words\n",
    "print(\"\\nThe first 5 words in the tokenized and tagged version are:\")\n",
    "print(brown_twords[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first two sentences\n",
    "print(\"\\nThe first 2 sentences in the sentence segmented, tokenized and tagged version are:\")\n",
    "print(brown_tsents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of all the tags in the brown corpus\n",
    "brown_tags = set([tag for (token,tag) in brown_twords])\n",
    "print(\"\\nThe set of all original tags in the brown orpus is:\")\n",
    "print(brown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of all the tags in the universal tagset\n",
    "brown_utwords = brown.tagged_words(categories='news',tagset='universal')\n",
    "universal_tags = set([tag for (token,tag) in brown_utwords])\n",
    "print(\"\\nThe set of universal tags is:\")\n",
    "print(universal_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train and evaluate several different taggers:\n",
    "\n",
    "- default\n",
    "- affix\n",
    "- unigram\n",
    "- bigram\n",
    "- trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default tagger\n",
    "\n",
    "# Get the sentence segmented and tokenized version of \"news\"\n",
    "# This is the non-part of speech tagged version that we will be tagging\n",
    "brown_sents = brown.sents(categories='news')\n",
    "\n",
    "# Get a list of all tags in the corpus\n",
    "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
    "\n",
    "# Get the most frequent tag in the corpus\n",
    "most_frequent_tag = nltk.FreqDist(tags).max()\n",
    "\n",
    "# Print the most frequent tag:\n",
    "print(most_frequent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a default tagger\n",
    "# The default tagger assigns the same \"default\" tag to every token in the corpus\n",
    "# We configure it to annotate with the most frequent tag\n",
    "default_tagger = nltk.DefaultTagger(most_frequent_tag)\n",
    "\n",
    "my_sent = \"the quick brown fox jumped over the lazy dog\".split()\n",
    "print(\"The sentence tagged with default tagger:\")\n",
    "print(default_tagger.tag(my_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the default tagger on the corpus:\n",
    "print(\"The accuracy of the default tagger on the corpus is:\")\n",
    "print(round(default_tagger.evaluate(brown_tsents),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the rest of the taggers, we will split the corpus to train and test\n",
    "test_corpus = brown_tsents[:1000]\n",
    "train_corpus = brown_tsents[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the affix tagger\n",
    "affix_tagger = AffixTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the affix tagger\n",
    "affix_sents = affix_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with affix tagger:\")\n",
    "print(affix_sents[0])\n",
    "print(\"\\nThe accuracy of the affix tagger on the corpus is:\")\n",
    "print(round(affix_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the unigram tagger\n",
    "unigram_tagger = UnigramTagger(train_corpus) \n",
    "\n",
    "# Tag the corpus with the unigram tagger\n",
    "uni_sents = unigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with unigram tagger:\")\n",
    "print(uni_sents[0])\n",
    "print(\"\\nThe accuracy of the unigram tagger on the corpus is:\")\n",
    "print(round(unigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram tagger\n",
    "bigram_tagger = BigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the bigram tagger\n",
    "bi_sents = bigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with bigram tagger:\")\n",
    "print(bi_sents[0])\n",
    "print(\"\\nThe accuracy of the bigram tagger on the corpus is:\")\n",
    "print(round(bigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the trigram tagger\n",
    "trigram_tagger = TrigramTagger(train_corpus)\n",
    "\n",
    "# Tag the corpus with the trigram tagger\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "tri_sents = trigram_tagger.tag_sents(brown_sents)\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with trigram tagger:\")\n",
    "print(tri_sents[0])\n",
    "print(\"\\nThe accuracy of the trigram tagger on the corpus is:\")\n",
    "print(round(trigram_tagger.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the bigram tagger with backoff\n",
    "bigram_tagger_backoff = BigramTagger(train_corpus,backoff=unigram_tagger)\n",
    "\n",
    "# Tag the corpus with the bigram tagger with backoff\n",
    "bi_sents_bo = bigram_tagger_backoff.tag_sents(brown_sents)\n",
    "\n",
    "\n",
    "# Print the first sentence and accuracy\n",
    "print(\"\\nThe first sentence, tagged with bigram taggerwith backoff:\")\n",
    "print(bi_sents_bo[0])\n",
    "print(\"\\nThe accuracy of the bigram tagger with backoff on the corpus is:\")\n",
    "print(round(bigram_tagger_backoff.evaluate(test_corpus),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# Train and test on the same corpus instead of using different ones\n",
    "# What is the result?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Create a sequence of backoff taggers:\n",
    "# trigram -> bigram -> unigram -> affix -> default\n",
    "# evaluate the resulting tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Try cross-domain tagging:\n",
    "# Train the corpus on \"news\" and evaluate it on \"science_fiction\"\n",
    "# Compare the results with a corpus trained and evaluated on the same domain (science_fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "# Importance of tagset\n",
    "# Rerun tasks 2 and 3 using \"universal\" tagset of the corpus\n",
    "# Compare the performance on \"universal\" and full tagset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
